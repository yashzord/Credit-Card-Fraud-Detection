{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec9ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try to figuree out about indexing for group by\n",
    "#group by merchant category as well so for example we have travel category and we should be able to show the divisons of diff airlines and stuff \n",
    "#keep track of mcg table as well from dontu sir\n",
    "#voice commands support for the visualization part\n",
    "#spherical data visulation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4aba8065",
   "metadata": {},
   "source": [
    "### **Import Libraries:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0adf34b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, FunctionTransformer, LabelBinarizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline # Note that this Pipeline is imported from imblearn, not sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73b83826",
   "metadata": {},
   "source": [
    "### **Set Pandas Display Options:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d1b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "023972e5",
   "metadata": {},
   "source": [
    "### Connect to SQLite Database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4282a8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(r\"C:\\Users\\yashu\\OneDrive\\Desktop\\Github_Projects\\Credit_Card_Fraud_Detection\\corecard_credit_card_transactions.db\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba954dc0",
   "metadata": {},
   "source": [
    "### Load Data from Database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbad381",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"SELECT * FROM transactions\", conn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a83b387b",
   "metadata": {},
   "source": [
    "### Database Visualization and Info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b545ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc6f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    print(f\"Unique values in {column}: {df[column].unique()}\")\n",
    "    print(f\"Number of unique values in {column}: {df[column].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61162e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79af5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with all null values\n",
    "all_null_columns = df.columns[df.isnull().all()]\n",
    "print(f\"Columns with all values null: {all_null_columns}\")\n",
    "print(f\"Number of columns with all values null: {len(all_null_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092be20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13af6833",
   "metadata": {},
   "source": [
    "### Fraud Only Database and Info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c95833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values in the 'FraudIndicator' column\n",
    "df['FraudIndicator'] = df['FraudIndicator'].fillna(0)\n",
    "\n",
    "fraud = pd.read_sql(\"SELECT * FROM transactions WHERE FraudIndicator = 1\", conn)                                  \n",
    "fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9456fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of fraud cases\n",
    "535908-535470"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ab919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross checking\n",
    "count_of_fraud_equal_to_1 = sum(df['FraudIndicator'] == 1.0)\n",
    "print(f\"Count of fraud equal to 1: {count_of_fraud_equal_to_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f88d706",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FraudIndicator'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5172838e",
   "metadata": {},
   "source": [
    "### Training and Validation Database (90% of Original Database) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19360012",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_sql(\"SELECT * FROM transactions ORDER BY TranTime LIMIT ROUND((SELECT COUNT(*) FROM transactions) * 0.9)\", conn)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a883d094",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d3b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values in the 'FraudIndicator' column\n",
    "data['FraudIndicator'] = data['FraudIndicator'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d77ca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross checking\n",
    "count_of_fraud_equal_to_1 = sum(data['FraudIndicator'] == 1.0)\n",
    "print(f\"Count of fraud equal to 1: {count_of_fraud_equal_to_1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23562a2e",
   "metadata": {},
   "source": [
    "### Preprocessing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42209e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into feature matrix X and target variable y\n",
    "X = data.drop('FraudIndicator', axis=1)\n",
    "y = data['FraudIndicator']\n",
    "\n",
    "# Define numerical, categorical, and nominal data columns\n",
    "numerical_data = ['TransactionAmount', 'OutstandingAmount', 'CurrentBalance', 'TotalOutStgAuthAmt', 'ActualReversalAmount', 'CalcOTB', 'ATC']\n",
    "categorical_data = ['TranType', 'PrimaryCurrencyCode', 'MessageTypeIdentifier', 'ProcCode', 'ProcCodeFromAccType', 'MerchantType', 'IResponseCode', 'ResponseCode', 'AuthStatus', 'POSTransactionStatusInd', 'TxnCategory', 'AdvReasonCode', 'AVResponse', 'PostingRef', 'TerminalType', 'Field112', 'AuthVarianceException', 'TxnSubCategory', 'PinExist', 'CardAcceptorNameLocation', 'CrossBorderTxnIndicator', 'MerchantName']\n",
    "nominal_data = ['TxnAcctId', 'UniqueID', 'AccountNumber']\n",
    "date_time = ['TranTime', 'PostTime', 'TransmissionDateTime', 'TimeLocalTransaction', 'DateLocalTransaction', 'EffectiveDate_ForAgeOff', 'PurgeDate']\n",
    "\n",
    "print(f\"Number of numerical data columns: {len(numerical_data)}\")\n",
    "print(f\"Number of categorical data columns: {len(categorical_data)}\")\n",
    "print(f\"Number of nominal data columns: {len(nominal_data)}\")\n",
    "print(f\"Number of date_time columns: {len(date_time)}\")\n",
    "\n",
    "# Define preprocessing pipelines\n",
    "num_pipe = Pipeline([\n",
    "    ('num_imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())  \n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    ('cat_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "    ('num', num_pipe, numerical_data),\n",
    "    ('cat', cat_pipe, categorical_data)\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6553cb1b",
   "metadata": {},
   "source": [
    "### Train and Evaluate the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6799ceeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SMOTE(random_state=42)' (type <class 'imblearn.over_sampling._smote.base.SMOTE'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 15\u001b[0m\n\u001b[0;32m      8\u001b[0m model \u001b[39m=\u001b[39m Pipeline([\n\u001b[0;32m      9\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mpreprocess\u001b[39m\u001b[39m'\u001b[39m, preprocessing),\n\u001b[0;32m     10\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39msmote\u001b[39m\u001b[39m'\u001b[39m, SMOTE(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)),\n\u001b[0;32m     11\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mclassifier\u001b[39m\u001b[39m'\u001b[39m, RandomForestClassifier())\n\u001b[0;32m     12\u001b[0m ])\n\u001b[0;32m     14\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     17\u001b[0m \u001b[39m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m     18\u001b[0m accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mscore(X_test, y_test)\n",
      "File \u001b[1;32mc:\\Users\\PrajwalSaokar\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:401\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \n\u001b[0;32m    377\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m--> 401\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps)\n\u001b[0;32m    402\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[0;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\PrajwalSaokar\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:339\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps):\n\u001b[0;32m    337\u001b[0m     \u001b[39m# shallow copy of steps - this should really be steps_\u001b[39;00m\n\u001b[0;32m    338\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps)\n\u001b[1;32m--> 339\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_steps()\n\u001b[0;32m    340\u001b[0m     \u001b[39m# Setup the memory\u001b[39;00m\n\u001b[0;32m    341\u001b[0m     memory \u001b[39m=\u001b[39m check_memory(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory)\n",
      "File \u001b[1;32mc:\\Users\\PrajwalSaokar\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:230\u001b[0m, in \u001b[0;36mPipeline._validate_steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    227\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mhasattr\u001b[39m(t, \u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(t, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\n\u001b[0;32m    228\u001b[0m         t, \u001b[39m\"\u001b[39m\u001b[39mtransform\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m     ):\n\u001b[1;32m--> 230\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    231\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAll intermediate steps should be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtransformers and implement fit and transform \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mor be the string \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    234\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m (type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (t, \u001b[39mtype\u001b[39m(t))\n\u001b[0;32m    235\u001b[0m         )\n\u001b[0;32m    237\u001b[0m \u001b[39m# We allow last estimator to be None as an identity transformation\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    239\u001b[0m     estimator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[39mand\u001b[39;00m estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    241\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    242\u001b[0m ):\n",
      "\u001b[1;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SMOTE(random_state=42)' (type <class 'imblearn.over_sampling._smote.base.SMOTE'>) doesn't"
     ]
    }
   ],
   "source": [
    "# Initialize the classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10, shuffle=True)\n",
    "\n",
    "# Create the pipeline\n",
    "model = ImbPipeline([\n",
    "    ('preprocess', preprocessing),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Model accuracy: {accuracy}\")\n",
    "\n",
    "# Make predictions\n",
    "y_predicted = model.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26553f7f",
   "metadata": {},
   "source": [
    "### Calculate Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f473d70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the F1 score\n",
    "f1_scores = f1_score(y_test, y_predicted, average=None)\n",
    "binary_f1_score = f1_score(y_test, y_predicted, average='binary')\n",
    "print(f\"F1 scores for each class: {f1_scores}\")\n",
    "print(f\"Binary F1 score: {binary_f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aca24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probs\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "\n",
    "\n",
    "probs = model.predict_proba(X_test)\n",
    "\n",
    "# Calculate average precision \n",
    "average_precision = average_precision_score(y_test, y_predicted)\n",
    "\n",
    "# Obtain precision and recall \n",
    "precision, recall, _ = precision_recall_curve(y_test, y_predicted)\n",
    "\n",
    "# Plot the recall precision tradeoff\n",
    "#plot_pr_curve(recall, precision, average_precision)\n",
    "\n",
    "# Print the roc auc score, the classification report and confusion matrix\n",
    "print(\"auc roc score: \", roc_auc_score(y_test, probs[:,1]))\n",
    "print('Classifcation report:\\n', classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af59f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_predicted)\n",
    "\n",
    "# Extract true positives, true negatives, false positives, and false negatives from the confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Calculate metrics in terms of percentages\n",
    "accuracy = accuracy_score(y_test, y_predicted) * 100\n",
    "precision = precision_score(y_test, y_predicted) * 100\n",
    "recall = recall_score(y_test, y_predicted) * 100\n",
    "f1 = f1_score(y_test, y_predicted) * 100\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1-Score: {f1:.2f}%\")\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a623dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "class_names = [False, True]\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "sns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"YlGnBu\", fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = [0.5, 1.5]\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "baf2076c",
   "metadata": {},
   "source": [
    "### Additional Queries and Data Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5f7304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for merchant types and total transaction amounts\n",
    "merchant_types_query = \"SELECT MerchantType, COUNT(1), SUM(TransactionAmount) as TotalAmount FROM transactions GROUP BY MerchantType ORDER BY TotalAmount DESC\"\n",
    "merchant_types_data = pd.read_sql(merchant_types_query, conn)\n",
    "print(merchant_types_data)\n",
    "\n",
    "# Query for transactions with missing MerchantType\n",
    "missing_merchant_type_query = \"SELECT MessageTypeIdentifier, * FROM transactions WHERE MerchantType IS NULL\"\n",
    "missing_merchant_type_data = pd.read_sql(missing_merchant_type_query, conn)\n",
    "print(missing_merchant_type_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5a7e080",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['FraudIndicator'] = data['FraudIndicator'].fillna(0)\n",
    "# Split data into feature matrix X and target variable y\n",
    "X = data.drop('FraudIndicator', axis=1)\n",
    "y = data['FraudIndicator']\n",
    "\n",
    "# Define numerical, categorical, and nominal data columns\n",
    "numerical_data = ['TransactionAmount', 'OutstandingAmount', 'CurrentBalance', 'TotalOutStgAuthAmt', 'ActualReversalAmount', 'CalcOTB', 'ATC']\n",
    "categorical_data = ['TranType', 'PrimaryCurrencyCode', 'MessageTypeIdentifier', 'ProcCode', 'ProcCodeFromAccType', 'MerchantType', 'IResponseCode', 'ResponseCode', 'AuthStatus', 'POSTransactionStatusInd', 'TxnCategory', 'AdvReasonCode', 'AVResponse', 'PostingRef', 'TerminalType', 'Field112', 'AuthVarianceException', 'TxnSubCategory', 'PinExist', 'CardAcceptorNameLocation', 'CrossBorderTxnIndicator', 'MerchantName']\n",
    "nominal_data = ['TxnAcctId', 'UniqueID', 'AccountNumber']\n",
    "date_time = ['TranTime', 'PostTime', 'TransmissionDateTime', 'TimeLocalTransaction', 'DateLocalTransaction', 'EffectiveDate_ForAgeOff', 'PurgeDate']\n",
    "\n",
    "# Define preprocessing pipelines\n",
    "num_pipe = Pipeline([\n",
    "    ('num_imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())  \n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    ('cat_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "    ('num', num_pipe, numerical_data),\n",
    "    ('cat', cat_pipe, categorical_data)\n",
    "])\n",
    "\n",
    "x = preprocessing.transform(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb31bb0c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
